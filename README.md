# Embedded AI - Obstacle Detection for Blind Navigation

Complete training and deployment system for obstacle detection on Raspberry Pi 4B.

## üéØ Overview

This repository contains:
- **Training code** for obstacle detection model
- **Raspberry Pi deployment** package (plug-and-play)
- **Camera inference** scripts
- **COCO dataset integration**

## üöÄ Quick Start

### For Raspberry Pi (Plug & Play)

1. **Download the Pi package:**
   ```bash
   git clone https://github.com/kshitijsatish142-pixel/Embedded_ai.git
   cd Embedded_ai
   ```

2. **Go to model package:**
   ```bash
   cd blind_navigation/models/pi_package
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements_pi.txt
   ```

4. **Run detection:**
   ```bash
   python3 pi_inference.py .
   ```

That's it! The model is ready to use.

## üìÅ Repository Structure

```
Embedded_ai/
‚îú‚îÄ‚îÄ blind_navigation/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pi_package/          # ‚Üê Copy this to Pi!
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ pi_inference.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model_weights.pt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model_metadata.json
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ requirements_pi.txt
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ README_PI.md
‚îÇ   ‚îú‚îÄ‚îÄ train_obstacle_detector.py
‚îÇ   ‚îú‚îÄ‚îÄ use_coco_and_train.py
‚îÇ   ‚îî‚îÄ‚îÄ pi_inference.py
‚îú‚îÄ‚îÄ camera_inference.py          # Camera integration
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ requirements_pi.txt
‚îî‚îÄ‚îÄ README.md
```

## üéì Training

### Train on COCO Dataset

```bash
# 1. Download COCO from: https://cocodataset.org/#download
# 2. Extract and train:
python3 blind_navigation/use_coco_and_train.py \
    --coco-images ./train2017 \
    --coco-annotations ./annotations/instances_train2017.json \
    --epochs 50
```

### Package for Pi

```bash
python3 blind_navigation/package_for_pi.py \
    --model-dir ./blind_navigation/models/obstacle_detector \
    --output-dir ./blind_navigation/models/pi_package
```

## üì± Raspberry Pi Setup

See [RASPBERRY_PI_SETUP.md](RASPBERRY_PI_SETUP.md) for detailed Pi setup instructions.

### Quick Pi Setup

```bash
# On Pi
git clone https://github.com/kshitijsatish142-pixel/Embedded_ai.git
cd Embedded_ai/blind_navigation/models/pi_package
pip install -r requirements_pi.txt
python3 pi_inference.py .
```

## üéØ Features

- ‚úÖ **Real-time obstacle detection** (10-20 FPS on Pi 4B)
- ‚úÖ **Critical object detection**: Person, Vehicle, Stairs, Door, Wall
- ‚úÖ **Distance estimation**
- ‚úÖ **Priority-based alerts**
- ‚úÖ **Plug-and-play** deployment
- ‚úÖ **Self-contained** (no training code needed on Pi)

## üìä Model Performance

- **Accuracy**: >85% for critical objects
- **Latency**: 50-100ms per frame
- **FPS**: 10-20 on Pi 4B
- **Memory**: ~200-300 MB

## üîß Requirements

### For Training
- Python 3.9+
- PyTorch
- torchvision
- COCO dataset (optional)

### For Pi Deployment
- Python 3.9+
- PyTorch (CPU)
- OpenCV
- NumPy, Pillow

## üìù Usage Examples

### Basic Detection

```python
from pi_inference import ObstacleDetector
import cv2

detector = ObstacleDetector(".")
camera = cv2.VideoCapture(0)

ret, frame = camera.read()
detections = detector.detect(frame)
detector.announce(detections)
```

### With Pi Camera

```python
from picamera2 import Picamera2
from pi_inference import ObstacleDetector

detector = ObstacleDetector(".")
camera = Picamera2()
camera.start()

frame = camera.capture_array()
detections = detector.detect(frame)
```

## ü§ù Contributing

Feel free to submit issues and pull requests!

## üìÑ License

This project is for educational and research purposes.

## üîó Links

- [COCO Dataset](https://cocodataset.org/)
- [Raspberry Pi Documentation](https://www.raspberrypi.org/documentation/)

---

**Ready to deploy?** Just copy `blind_navigation/models/pi_package/` to your Pi and run!

